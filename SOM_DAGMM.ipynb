{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "\n",
    "from minisom import MiniSom\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from som_dagmm.model import DAGMM, SOM_DAGMM\n",
    "from som_dagmm.compression_network import CompressionNetwork\n",
    "from som_dagmm.estimation_network import EstimationNetwork\n",
    "from som_dagmm.gmm import GMM, Mixture\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from SOM import som_train, som_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "\n",
    "# epochs = 100\n",
    "batch_size = 1024\n",
    "save_path = 'saves/save/epoch_'\n",
    "dataset = 'IDS2018'\n",
    "features = 'numerical'\n",
    "embed = 'label_encode'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'IDS2018':\n",
    "    data = load_data('data/CSE-CIC-IDS2018/CSE-CIC-IDS2018-25k.csv')\n",
    "    # data = load_data('data/NEW-CSE-CIC-IDS2018/new-500k.csv')\n",
    "\n",
    "    dataB = data[(data['Label'] ==  \"Benign\")] #Pegando somente os benignos\n",
    "    dataM = data[(data['Label'] !=  \"Benign\")]\n",
    "    categorical_cols = []\n",
    "    YB = get_labels(dataB, dataset)\n",
    "    YM = get_labels(dataM, dataset)\n",
    "\n",
    "if dataset == 'kdd':\n",
    "    names = [i for i in range(0,43)] # Qtd de colunas, cada coluna está representada entre 0 a 42\n",
    "    data = load_data('data/NSL-KDD/KDDTrain+.txt', names)\n",
    "\n",
    "    data = data[(data[41] ==  \"normal\")]\n",
    "\n",
    "    categorical_cols = [1,2,3] # Somente as colunas 1,2,3\n",
    "    Y = get_labels(data, dataset)\n",
    "    categorical_cols = [1,2,3] # Somente as colunas 1,2,3\n",
    "    Y = get_labels(data, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dataB = dataB\n",
    "save_dataM = dataM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataB = save_dataB\n",
    "dataM = save_dataM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = save_dataM\n",
    "Y = YM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select features\n",
    "if features == \"categorical\":\n",
    "    data = data[categorical_cols]\n",
    "    dataB = dataB[categorical_cols]\n",
    "if features == \"numerical\":\n",
    "    data = remove_cols(data, categorical_cols)\n",
    "    dataB = remove_cols(dataB, categorical_cols)\n",
    "\n",
    "#encode categorical variables\n",
    "if embed == 'one_hot':\n",
    "    data = one_hot_encoding(data, categorical_cols)\n",
    "    dataB = one_hot_encoding(dataB, categorical_cols)\n",
    "if embed == 'label_encode':\n",
    "    data = label_encoding(data, categorical_cols)\n",
    "    dataB = one_hot_encoding(dataB, categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo uma seed para serpação dos dados\n",
    "#Podemos validar o modelo\n",
    "# seed = 123\n",
    "# np.random.seed(seed)\n",
    "\n",
    "# num_samples = int(0.01 * len(data))\n",
    "\n",
    "# # Gerando índices aleatórios\n",
    "# random_indices = np.random.choice(len(data), num_samples, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.iloc[random_indices]\n",
    "# Y = Y[random_indices]\n",
    "\n",
    "print(data.shape[0])\n",
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns with NA values\n",
    "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "dataB.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "data = fill_na(data)\n",
    "dataB = fill_na(dataB)\n",
    "\n",
    "# normalize data\n",
    "data = normalize_cols(data)\n",
    "dataB = normalize_cols(dataB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test and train split\n",
    "train_data, test_data, Y_train, Y_test = split_data(data, Y, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.concat([test_data, dataB], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = np.concatenate([Y_test, YB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(train_data.index[-1])\n",
    "# Y_test = Y_test[:-1]\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(Y_train))\n",
    "print(len(test_data))\n",
    "print(len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to torch tensors\n",
    "dataX = torch.tensor(data.values.astype(np.float32))\n",
    "train_dataT = torch.tensor(train_data.values.astype(np.float32))\n",
    "test_dataT = torch.tensor(test_data.values.astype(np.float32))\n",
    "\n",
    "#Convert tensor to TensorDataset class.\n",
    "dataset = TensorDataset(train_dataT)\n",
    "\n",
    "#TrainLoader\n",
    "dataloader = DataLoader(train_dataT, batch_size= batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_som = som_train(data=train_dataT, x=10, y=10, sigma=1, learning_rate=0.8, iters=10000, neighborhood_function= 'gaussian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression = CompressionNetwork(dataX.shape[1])\n",
    "estimation = EstimationNetwork()\n",
    "gmm = GMM(2,6)\n",
    "mix = Mixture(6)\n",
    "dagmm = DAGMM(compression, estimation, gmm)\n",
    "net = SOM_DAGMM(dagmm, pretrained_som)\n",
    "optimizer =  optim.Adam(net.parameters(), lr=0.0001)\n",
    "for epoch in range(epochs):\n",
    "    print('EPOCH {}:'.format(epoch + 1))\n",
    "    running_loss = 0\n",
    "    for i, data in enumerate(dataloader):\n",
    "        out = net(data)\n",
    "        # optimizer.zero_grad()\n",
    "        L_loss = compression.reconstruction_loss(data[0])\n",
    "        G_loss = mix.gmm_loss(out=out, L1=0.1, L2=0.005)\n",
    "\n",
    "        loss = L_loss + G_loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if torch.isfinite(loss):\n",
    "            running_loss += loss.item()\n",
    "            print(f\"LOSS: {loss.item()} - L: {L_loss} - G: {G_loss}\")\n",
    "        else:\n",
    "            print(f\"ERROR: {loss.item()} - L: {L_loss} - G: {G_loss}\")\n",
    "\n",
    "\n",
    "    # Avalia o resultado do treinamento a cada epoch\n",
    "    net.eval()\n",
    "    out_ = net(test_dataT)\n",
    "    threshold = np.percentile(out_, 20)\n",
    "    pred = (out_ > threshold).numpy().astype(int)\n",
    "\n",
    "    # Precision, Recall, F1\n",
    "    a, p, r, f, auc = get_scores(pred, Y_test)\n",
    "    print(\"Accuracy:\", a, \"Precision:\", p, \"Recall:\", r, \"F1 Score:\", f, \"AUROC:\", auc)\n",
    "        \n",
    "    print(running_loss)\n",
    "\n",
    "    if (epoch+1) % 5 == 0:\n",
    "        path = save_path + str(epoch+1)\n",
    "        torch.save(net, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
